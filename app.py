import streamlit as st
import easyocr
import numpy as np
import cv2
from PIL import Image
import random

# === â˜…è¿½åŠ ï¼šUÂ²â€‘NetP é–¢é€£ ===
import os, zipfile
from pathlib import Path
import torch
from torchvision import transforms
import gdown

# === å®šæ•° ===
GRID_SIZE = 10
CELL_SIZE = 80
IMAGE_SIZE = 800
OCCUPANCY_THRESHOLD = 0.05
PACKAGE_TEXT_THRESHOLD = 0.80          # ãƒã‚¹ã‚¯å†…ç‡ 80% ä»¥ä¸Šãªã‚‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ã¨ã¿ãªã™

# === â˜…è¿½åŠ ï¼šUÂ²â€‘NetP ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å…ˆ ===
MODEL_DIR   = Path(__file__).parent / "models"
MODEL_DIR.mkdir(exist_ok=True)
U2NETP_PATH = MODEL_DIR / "u2netp.pth"
U2NETP_URL  = "https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy"

st.set_page_config(layout="wide")
st.title("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆvar.250415 + mask2ï¼‰")

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ç”¨ã‚­ãƒ¼ã®åˆæœŸåŒ– ---
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0

# --- OCR åˆæœŸåŒ– ---
@st.cache_resource
def load_reader():
    return easyocr.Reader(['ja'], gpu=False, recog_network='japanese_g2')
reader = load_reader()

# === â˜…ä¿®æ­£ï¼šUÂ²â€‘NetP ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã«å±•é–‹ã—ã¦ãƒ­ãƒ¼ãƒ‰ ===
@st.cache_resource
def load_u2net():
    # 1) é‡ã¿ãŒãªã‘ã‚Œã°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ4.7â€¯MBï¼‰
    if not U2NETP_PATH.exists():
        gdown.download(U2NETP_URL, str(U2NETP_PATH), quiet=False)

    # 2) hubconf ã‚’ãƒ­ãƒ¼ã‚«ãƒ«å±•é–‹
    repo = MODEL_DIR / "U-2-Net"
    if not repo.exists():
        zip_path = MODEL_DIR / "u2net.zip"
        torch.hub.download_url_to_file(
            "https://github.com/NathanUA/U-2-Net/archive/refs/heads/master.zip",
            str(zip_path))
        with zipfile.ZipFile(zip_path) as z:
            z.extractall(MODEL_DIR)

    # 3) ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
    model = torch.hub.load(str(repo), "u2netp", pretrained=False, source='local')
    model.load_state_dict(torch.load(U2NETP_PATH, map_location='cpu'))
    model.eval()
    return model

# === â˜…è¿½åŠ ï¼šå•†å“ãƒã‚¹ã‚¯ç”Ÿæˆ ===
def get_product_mask(pil_img):
    model = load_u2net()
    tr = transforms.Compose([
        transforms.Resize((320, 320)),
        transforms.ToTensor(),
        transforms.Normalize([0.5]*3, [0.5]*3)
    ])
    inp = tr(pil_img).unsqueeze(0)
    with torch.no_grad():
        pred = model(inp)[0][0]
    mask = (pred.sigmoid().cpu().numpy() > 0.5).astype(np.uint8)
    mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3,3), np.uint8))
    return mask  # 0/1 ãƒã‚¹ã‚¯

# --- OCR ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ã‚»ãƒ«ã®é‡ãªã‚Šåˆ¤å®š ---
def get_cells_from_box(x1, y1, x2, y2, threshold=OCCUPANCY_THRESHOLD):
    cells = set()
    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            cx1, cy1 = col * CELL_SIZE, row * CELL_SIZE
            cx2, cy2 = cx1 + CELL_SIZE, cy1 + CELL_SIZE
            ix1, iy1 = max(x1, cx1), max(y1, cy1)
            ix2, iy2 = min(x2, cx2), min(y2, cy2)
            iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
            inter = iw * ih
            area = (x2 - x1) * (y2 - y1)
            if area > 0 and inter / area >= threshold:
                cells.add(f"{row+1}-{col+1}")
    return cells

# --- ã‚°ãƒªãƒƒãƒ‰å…¨ä½“ã®ã‚»ãƒ«é›†åˆ ---
def get_all_cells():
    return {f"{row}-{col}" for row in range(1, GRID_SIZE+1) for col in range(1, GRID_SIZE+1)}

# --- è¡Œã”ã¨ã«ã‚»ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆè¡¨ç¤ºç”¨ï¼‰ ---
def group_cells_by_row(cells):
    d = {str(r): [] for r in range(1, GRID_SIZE+1)}
    for c in sorted(cells, key=lambda x: (int(x.split('-')[0]), int(x.split('-')[1]))):
        r, _ = c.split('-')
        d[r].append(c)
    return list(d.values())

# --- ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”» ---
def draw_overlay(img, occupied, target, excluded, mask=None):
    vis = np.array(img).copy()
    overlay = vis.copy()
    # â˜…è¿½åŠ ï¼šå•†å“ãƒã‚¹ã‚¯è¼ªéƒ­
    if mask is not None:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(vis, contours, -1, (255, 255, 255), 2)

    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            x, y = col * CELL_SIZE, row * CELL_SIZE
            cid = f"{row+1}-{col+1}"
            if cid in excluded:
                color = (255, 100, 100)
                cv2.rectangle(overlay, (x, y), (x+CELL_SIZE, y+CELL_SIZE), color, -1)
            elif cid in target:
                color = (0, 255, 0)
                cv2.rectangle(overlay, (x, y), (x+CELL_SIZE, y+CELL_SIZE), color, -1)
            elif cid in (set(occupied) - set(excluded)):
                color = (100, 180, 255)
                cv2.rectangle(overlay, (x, y), (x+CELL_SIZE, y+CELL_SIZE), color, -1)
            cv2.rectangle(vis, (x, y), (x+CELL_SIZE, y+CELL_SIZE), (0, 255, 0), 1)
            cv2.putText(vis, cid, (x+4, y+15),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    return cv2.addWeighted(overlay, 0.5, vis, 0.5, 0)

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---
def apply_excluded():
    st.session_state["excluded_cells"] = st.session_state.get("temp_excluded", [])

def apply_target():
    st.session_state["target_cells"] = st.session_state.get("temp_target", [])

# --- ãƒªã‚»ãƒƒãƒˆå‡¦ç† ---
def reset_image():
    for key in ["uploaded", "image_data", "product_mask", "occupied_cells",
                "excluded_cells", "temp_excluded", "target_cells", "temp_target"]:
        st.session_state.pop(key, None)
    st.session_state["uploader_key"] += 1
    st.set_query_params(dummy=str(random.randint(0, 100000)))

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ ---
uploaded = st.file_uploader(
    "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=["jpg", "png", "jpeg"],
    key=f"uploader_{st.session_state['uploader_key']}"
)
if uploaded:
    st.session_state["uploaded"] = uploaded

# --- ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼†OCRå‡¦ç†ï¼ˆåˆå›ã®ã¿ï¼‰ ---
if st.session_state.get("uploaded") and st.session_state.get("image_data") is None:
    img = Image.open(st.session_state["uploaded"]).convert("RGB").resize((IMAGE_SIZE, IMAGE_SIZE))
    product_mask = get_product_mask(img)            # â˜…è¿½åŠ 
    arr = np.array(img)
    results = reader.readtext(arr)

    occ = set()
    for bbox, text, conf in results:
        if not text.strip():
            continue
        x1, y1 = int(bbox[0][0]), int(bbox[0][1])
        x2, y2 = int(bbox[2][0]), int(bbox[2][1])

        # â˜…è¿½åŠ ï¼šãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ãƒ•ã‚£ãƒ«ã‚¿
        region = product_mask[y1:y2, x1:x2]
        if region.size > 0 and region.mean() >= PACKAGE_TEXT_THRESHOLD:
            continue  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—

        occ |= get_cells_from_box(x1, y1, x2, y2)

    st.session_state["image_data"] = img
    st.session_state["product_mask"] = product_mask
    st.session_state["occupied_cells"] = sorted(occ)
    st.session_state["excluded_cells"] = []
    st.session_state["target_cells"] = []

# --- UI è¡¨ç¤º ---
img_data = st.session_state.get("image_data")
if img_data is not None:
    col1, col2 = st.columns([1.1, 1.2])
    with col1:
        occupied_set = set(st.session_state.get("occupied_cells", []))
        excluded_set = set(st.session_state.get("excluded_cells", []))
        target_set = set(st.session_state.get("target_cells", []))
        final_cells = (occupied_set - excluded_set) | target_set
        ratio = round(len(final_cells) / (GRID_SIZE * GRID_SIZE) * 100)
        status = "â­•ï¸ åˆæ ¼" if ratio <= 20 else ("â–² æ³¨æ„" if ratio <= 30 else "âŒ ä¸åˆæ ¼")
        st.markdown(f"ğŸ“Š **ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡: {ratio}%**")
        c_status, c_reset = st.columns([4, 1])
        with c_status:
            st.markdown(f"ğŸ“ **æœ€çµ‚åˆ¤å®šçµæœ: {status}**")
        with c_reset:
            if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
                reset_image()
        overlay_img = draw_overlay(
            img_data,
            st.session_state.get("occupied_cells", []),
            st.session_state.get("target_cells", []),
            st.session_state.get("excluded_cells", []),
            mask=st.session_state.get("product_mask")
        )
        st.image(overlay_img, caption="OCR + ã‚»ãƒ«ãƒãƒƒãƒ—", width=int(IMAGE_SIZE * 0.8))
    with col2:
        # ===== é™¤å¤–ãƒã‚¹ =====
        st.markdown("### ğŸ› ï¸ é™¤å¤–ãƒã‚¹ã‚’é¸æŠ")
        with st.form("form_exclusion"):
            if "temp_excluded" not in st.session_state:
                st.session_state["temp_excluded"] = list(st.session_state.get("excluded_cells", []))
            for row_cells in group_cells_by_row(st.session_state.get("occupied_cells", [])):
                if not row_cells:
                    continue
                with st.container():
                    cols = st.columns([0.1] * len(row_cells), gap="small")
                    for i, cid in enumerate(row_cells):
                        with cols[i]:
                            checked = cid in st.session_state.get("temp_excluded", [])
                            val = st.checkbox(cid, value=checked, key=f"exclude_{cid}")
                            if val and cid not in st.session_state["temp_excluded"]:
                                st.session_state["temp_excluded"].append(cid)
                            elif not val and cid in st.session_state["temp_excluded"]:
                                st.session_state["temp_excluded"].remove(cid)
            if st.form_submit_button("ğŸ”„ é™¤å¤–åæ˜ "):
                apply_excluded()
        st.markdown("---")
        # ===== å¯¾è±¡ãƒã‚¹ =====
        st.markdown("### ğŸ› ï¸ å¯¾è±¡ãƒã‚¹ã‚’é¸æŠ")
        all_cells = get_all_cells()
        candidate_cells = sorted(all_cells - set(st.session_state.get("occupied_cells", [])))
        if "temp_target" not in st.session_state:
            st.session_state["temp_target"] = list(st.session_state.get("target_cells", []))
        with st.form("form_target"):
            for row_cells in group_cells_by_row(candidate_cells):
                if not row_cells:
                    continue
                with st.container():
                    cols = st.columns([0.1] * len(row_cells), gap="small")
                    for i, cid in enumerate(row_cells):
                        with cols[i]:
                            checked = cid in st.session_state["temp_target"]
                            val = st.checkbox(cid, value=checked, key=f"target_{cid}")
                            if val and cid not in st.session_state["temp_target"]:
                                st.session_state["temp_target"].append(cid)
                            elif not val and cid in st.session_state["temp_target"]:
                                st.session_state["temp_target"].remove(cid)
            if st.form_submit_button("ğŸ”„ å¯¾è±¡åæ˜ "):
                apply_target()
else:
    st.info("ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
