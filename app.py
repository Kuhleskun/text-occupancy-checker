import streamlit as st
import easyocr
import numpy as np
import cv2
from PIL import Image
import random
import io

# === rembg (UÂ²â€‘NetP ONNX å†…è”µ) ===
from rembg import remove

# === å®šæ•° ===
GRID_SIZE = 10
CELL_SIZE = 80
IMAGE_SIZE = 800
OCCUPANCY_THRESHOLD = 0.05
PACKAGE_TEXT_THRESHOLD = 0.80  # ãƒã‚¹ã‚¯å†…ç‡ 80% ä»¥ä¸Šãªã‚‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ã¨ã¿ãªã™

st.set_page_config(layout="wide")
st.title("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆvar.250415 + mask_onnxï¼‰")

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ç”¨ã‚­ãƒ¼ã®åˆæœŸåŒ– ---
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0

# --- OCR åˆæœŸåŒ– ---
@st.cache_resource
def load_reader():
    return easyocr.Reader(['ja'], gpu=False, recog_network='japanese_g2')

reader = load_reader()

# === å•†å“ãƒã‚¹ã‚¯ç”Ÿæˆ (rembg åˆ©ç”¨ãƒ»å¤–éƒ¨ DL ä¸è¦) ===

def get_product_mask(pil_img):
    """rembg ã§å‰æ™¯ãƒã‚¹ã‚¯ (0/1 ndarray) ã‚’å–å¾—"""
    buf = io.BytesIO()
    pil_img.save(buf, format="PNG")
    mask_bytes = remove(buf.getvalue(), only_mask=True)
    mask_img = Image.open(io.BytesIO(mask_bytes)).convert("L")
    mask_img = mask_img.resize((IMAGE_SIZE, IMAGE_SIZE), Image.BILINEAR)
    mask = (np.array(mask_img) > 128).astype(np.uint8)
    # å°ã•ãªç©´ã‚’é–‰ã˜ã‚‹
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))
    return mask

# --- OCR ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã¨ã‚»ãƒ«ã®é‡ãªã‚Šåˆ¤å®š ---

def get_cells_from_box(x1, y1, x2, y2, threshold=OCCUPANCY_THRESHOLD):
    cells = set()
    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            cx1, cy1 = col * CELL_SIZE, row * CELL_SIZE
            cx2, cy2 = cx1 + CELL_SIZE, cy1 + CELL_SIZE
            ix1, iy1 = max(x1, cx1), max(y1, cy1)
            ix2, iy2 = min(x2, cx2), min(y2, cy2)
            iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
            inter = iw * ih
            area = (x2 - x1) * (y2 - y1)
            if area > 0 and inter / area >= threshold:
                cells.add(f"{row + 1}-{col + 1}")
    return cells

# --- ã‚°ãƒªãƒƒãƒ‰å…¨ä½“ã®ã‚»ãƒ«é›†åˆ ---

def get_all_cells():
    return {f"{row}-{col}" for row in range(1, GRID_SIZE + 1) for col in range(1, GRID_SIZE + 1)}

# --- è¡Œã”ã¨ã«ã‚»ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼ˆè¡¨ç¤ºç”¨ï¼‰ ---

def group_cells_by_row(cells):
    d = {str(r): [] for r in range(1, GRID_SIZE + 1)}
    for c in sorted(cells, key=lambda x: (int(x.split('-')[0]), int(x.split('-')[1]))):
        r, _ = c.split('-')
        d[r].append(c)
    return list(d.values())

# --- ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤æç”» ---

def draw_overlay(img, occupied, target, excluded, mask=None):
    vis = np.array(img).copy()
    overlay = vis.copy()
    # å•†å“ãƒã‚¹ã‚¯è¼ªéƒ­
    if mask is not None:
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(vis, contours, -1, (255, 255, 255), 2)

    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            x, y = col * CELL_SIZE, row * CELL_SIZE
            cid = f"{row + 1}-{col + 1}"
            if cid in excluded:
                color = (255, 100, 100)
                cv2.rectangle(overlay, (x, y), (x + CELL_SIZE, y + CELL_SIZE), color, -1)
            elif cid in target:
                color = (0, 255, 0)
                cv2.rectangle(overlay, (x, y), (x + CELL_SIZE, y + CELL_SIZE), color, -1)
            elif cid in (set(occupied) - set(excluded)):
                color = (100, 180, 255)
                cv2.rectangle(overlay, (x, y), (x + CELL_SIZE, y + CELL_SIZE), color, -1)
            cv2.rectangle(vis, (x, y), (x + CELL_SIZE, y + CELL_SIZE), (0, 255, 0), 1)
            cv2.putText(vis, cid, (x + 4, y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
    return cv2.addWeighted(overlay, 0.5, vis, 0.5, 0)

# --- ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ ---

def apply_excluded():
    st.session_state["excluded_cells"] = st.session_state.get("temp_excluded", [])

def apply_target():
    st.session_state["target_cells"] = st.session_state.get("temp_target", [])

# --- ãƒªã‚»ãƒƒãƒˆå‡¦ç† ---

def reset_image():
    for key in [
        "uploaded",
        "image_data",
        "product_mask",
        "occupied_cells",
        "excluded_cells",
        "temp_excluded",
        "target_cells",
        "temp_target",
    ]:
        st.session_state.pop(key, None)
    st.session_state["uploader_key"] += 1
    st.set_query_params(dummy=str(random.randint(0, 100000)))

# --- ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ€ãƒ¼ ---
uploaded = st.file_uploader(
    "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=["jpg", "png", "jpeg"],
    key=f"uploader_{st.session_state['uploader_key']}"
)
if uploaded:
    st.session_state["uploaded"] = uploaded

# --- ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼†OCRå‡¦ç†ï¼ˆåˆå›ã®ã¿ï¼‰ ---
if st.session_state.get("uploaded") and st.session_state.get("image_data") is None:
    img = Image.open(st.session_state["uploaded"]).convert("RGB").resize((IMAGE_SIZE, IMAGE_SIZE))
    product_mask = get_product_mask(img)
    arr = np.array(img)
    results = reader.readtext(arr)

    occ = set()
    for bbox, text, conf in results:
        if not text.strip():
            continue
        x1, y1 = int(bbox[0][0]), int(bbox[0][1])
        x2, y2 = int(bbox[2][0]), int(bbox[2][1])

        region = product_mask[y1:y2, x1:x2]
        if region.size > 0 and region.mean() >= PACKAGE_TEXT_THRESHOLD:
            continue  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—

        occ |= get_cells_from_box(x1, y1, x2, y2)

    st.session_state["image_data"] = img
    st.session_state["product_mask"] = product_mask
    st.session_state["occupied_cells"] = sorted(occ)
    st.session_state["excluded_cells"] = []
    st.session_state["target_cells"] = []

# --- UI è¡¨ç¤º ---
img_data = st.session_state.get("image_data")
if img_data is not None:
    col1, col2 = st.columns([1.1, 1.2])
    with col1:
        occupied_set = set(st.session_state.get("occupied_cells", []))
        excluded_set = set(st.session_state.get("excluded_cells", []))
        target_set = set(st.session_state.get("target_cells", []))
        final_cells = (occupied_set - excluded_set) | target_set
        ratio = round(len(final_cells) / (GRID_SIZE * GRID_SIZE) * 100)
        status = "â­•ï¸ åˆæ ¼" if ratio <= 20 else ("â–² æ³¨æ„" if ratio <= 30 else "âŒ ä¸åˆæ ¼")
        st.markdown(f"ğŸ“Š **ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡: {ratio}%**")
        c_status, c_reset = st.columns([4, 1])
        with c_status:
            st.markdown(f"ğŸ“ **æœ€çµ‚åˆ¤å®šçµæœ: {status}**")
        with c_reset:
            if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
                reset_image()
        overlay_img = draw_overlay(
            img_data,
            st.session_state.get("occupied_cells", []),
            st.session_state.get("target_cells", []),
            st.session_state.get("excluded_cells", []),
            mask=st.session_state.get("product_mask"),
        )
        st.image(overlay_img, caption="OCR + ã‚»ãƒ«ãƒãƒƒãƒ—", width=int(IMAGE_SIZE * 0.8))
    with col2:
        st.markdown("### ğŸ› ï¸ é™¤å¤–ãƒã‚¹ã‚’é¸æŠ")
        with st.form("form_exclusion"):
            if "temp_excluded" not in st.session_state:
                st.session_state["temp_excluded"] = list(st.session_state.get("excluded_cells", []))
            for row_cells in group_cells_by_row(st.session_state.get("occupied_cells", [])):
                if not row_cells:
                    continue
                with st.container():
                    cols = st.columns([0.1] * len(row_cells), gap="small")
                    for i, cid in enumerate(row_cells):
                        with cols[i]:
                            checked = cid in st.session_state["temp_excluded"]
                            val = st.checkbox(cid, value=checked, key=f"exclude
