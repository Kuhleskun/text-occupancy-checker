import streamlit as st
import easyocr
import numpy as np
import cv2
from PIL import Image
import random
from pathlib import Path
import torch
from torchvision import transforms


"""
Torchâ€‘based UÂ²â€‘NetP ã§å•†å“é ˜åŸŸãƒã‚¹ã‚¯ã‚’å–å¾—ã—ã€
ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—ã‚’é™¤å¤–ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡ã‚’è¨ˆç®—ã™ã‚‹ã‚¢ãƒ—ãƒªã€‚
ä¾å­˜è¿½åŠ ãªã—ï¼ˆtorch ã¯ easyocr ãŒå°å…¥ï¼‰
å¤–éƒ¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãªã—ï¼š`models/u2netp.pth` ã‚’åŒæ¢±ã—ã¦ãŠã
UIï¼ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¯å¾“æ¥é€šã‚Š
"""

# -------------------- å®šæ•° --------------------
GRID_SIZE = 10
CELL_SIZE = 80
IMAGE_SIZE = 800
OCCUPANCY_THRESHOLD = 0.05      # æ–‡å­— bbox ãŒã‚»ãƒ«ã« 5% ä»¥ä¸Šé‡ãªã‚Œã°å æœ‰
PACKAGE_TEXT_THRESHOLD = 0.80   # bbox ã® 80%ä»¥ä¸ŠãŒå•†å“ãƒã‚¹ã‚¯å†…ãªã‚‰ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—
MODEL_PATH = Path(__file__).parent / "models" / "u2netp.pth"  # 4.7â€¯MB é‡ã¿

st.set_page_config(layout="wide")
st.title("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡ãƒã‚§ãƒƒã‚«ãƒ¼ï¼ˆTorch UÂ²â€‘NetP å®Œå…¨ç‰ˆï¼‰")

# -------------------- OCR ãƒªãƒ¼ãƒ€ --------------------
@st.cache_resource
def load_reader():
    return easyocr.Reader(["ja"], gpu=False, recog_network="japanese_g2")

reader = load_reader()

# -------------------- UÂ²â€‘NetP ãƒ­ãƒ¼ãƒ‰ --------------------
@st.cache_resource
def load_u2netp():
    if not MODEL_PATH.exists():
        st.error("u2netp.pth ãŒ models/ ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()
    model = torch.hub.load("NathanUA/U-2-Net", "u2netp", pretrained=False)
    model.load_state_dict(torch.load(MODEL_PATH, map_location="cpu"))
    model.eval()
    return model

# -------------------- å•†å“ãƒã‚¹ã‚¯ --------------------

def get_product_mask(pil_img: Image.Image) -> np.ndarray:
    model = load_u2netp()
    tr = transforms.Compose([
        transforms.Resize((320, 320)),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),
    ])
    inp = tr(pil_img).unsqueeze(0)
    with torch.no_grad():
        pred = model(inp)[0][0]
    mask = (pred.sigmoid().cpu().numpy() > 0.5).astype(np.uint8)
    mask = cv2.resize(mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_LINEAR)
    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((3, 3), np.uint8))
    return mask

# -------------------- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ --------------------

def get_cells_from_box(x1, y1, x2, y2, threshold=OCCUPANCY_THRESHOLD):
    cells = set()
    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            cx1, cy1 = col * CELL_SIZE, row * CELL_SIZE
            cx2, cy2 = cx1 + CELL_SIZE, cy1 + CELL_SIZE
            ix1, iy1 = max(x1, cx1), max(y1, cy1)
            ix2, iy2 = min(x2, cx2), min(y2, cy2)
            iw, ih = max(0, ix2 - ix1), max(0, iy2 - iy1)
            inter = iw * ih
            area = (x2 - x1) * (y2 - y1)
            if area > 0 and inter / area >= threshold:
                cells.add(f"{row + 1}-{col + 1}")
    return cells


def get_all_cells():
    return {f"{r}-{c}" for r in range(1, GRID_SIZE + 1) for c in range(1, GRID_SIZE + 1)}


def group_cells_by_row(cells):
    rows = {str(r): [] for r in range(1, GRID_SIZE + 1)}
    for cid in sorted(cells, key=lambda x: (int(x.split('-')[0]), int(x.split('-')[1]))):
        r, _ = cid.split('-')
        rows[r].append(cid)
    return list(rows.values())


def draw_overlay(img, occupied, target, excluded, mask=None):
    vis = np.array(img).copy()
    overlay = vis.copy()

    if mask is not None:
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        cv2.drawContours(vis, cnts, -1, (255, 255, 255), 2)

    for row in range(GRID_SIZE):
        for col in range(GRID_SIZE):
            x, y = col * CELL_SIZE, row * CELL_SIZE
            cid = f"{row + 1}-{col + 1}"
            if cid in excluded:
                color = (255, 100, 100)
            elif cid in target:
                color = (0, 255, 0)
            elif cid in (set(occupied) - set(excluded)):
                color = (100, 180, 255)
            else:
                color = None
            if color is not None:
                cv2.rectangle(overlay, (x, y), (x + CELL_SIZE, y + CELL_SIZE), color, -1)
            cv2.rectangle(vis, (x, y), (x + CELL_SIZE, y + CELL_SIZE), (0, 255, 0), 1)
            cv2.putText(vis, cid, (x + 4, y + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)

    return cv2.addWeighted(overlay, 0.5, vis, 0.5, 0)

# -------------------- ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ˜ãƒ«ãƒ‘ --------------------

def reset_image():
    for k in [
        "uploaded", "image_data", "product_mask", "occupied_cells",
        "excluded_cells", "temp_excluded", "target_cells", "temp_target"
    ]:
        st.session_state.pop(k, None)
    st.session_state["uploader_key"] = st.session_state.get("uploader_key", 0) + 1
    st.set_query_params(dummy=str(random.randint(0, 100000)))

# -------------------- UI: ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ --------------------
if "uploader_key" not in st.session_state:
    st.session_state["uploader_key"] = 0

uploaded = st.file_uploader(
    "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„",
    type=["jpg", "png", "jpeg"],
    key=f"uploader_{st.session_state['uploader_key']}"
)
if uploaded:
    st.session_state["uploaded"] = uploaded

# -------------------- ç”»åƒå‡¦ç†ï¼ˆåˆå›ã®ã¿ï¼‰ --------------------
if st.session_state.get("uploaded") and st.session_state.get("image_data") is None:
    img = Image.open(st.session_state["uploaded"]).convert("RGB").resize((IMAGE_SIZE, IMAGE_SIZE))
    product_mask = get_product_mask(img)

    occ = set()
    for bbox, text, conf in reader.readtext(np.array(img)):
        if not text.strip():
            continue
        x1, y1 = map(int, bbox[0])
        x2, y2 = map(int, bbox[2])
        region = product_mask[y1:y2, x1:x2]
        if region.size > 0 and region.mean() >= PACKAGE_TEXT_THRESHOLD:
            continue  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ–‡å­—
        occ |= get_cells_from_box(x1, y1, x2, y2)

    st.session_state.update({
        "image_data": img,
        "product_mask": product_mask,
        "occupied_cells": sorted(occ),
        "excluded_cells": [],
        "target_cells": []
    })

# -------------------- UI è¡¨ç¤º --------------------
img_data = st.session_state.get("image_data")
if img_data is not None:
    col1, col2 = st.columns([1.1, 1.2])

    # ---------- å·¦ã‚«ãƒ©ãƒ  ----------
    with col1:
        occupied_set = set(st.session_state["occupied_cells"])
        excluded_set = set(st.session_state["excluded_cells"])
        target_set   = set(st.session_state["target_cells"])
        final_cells  = (occupied_set - excluded_set) | target_set
        ratio = round(len(final_cells))  # 100 ã‚»ãƒ«å›ºå®šãªã®ã§ count==%
        status = "â­•ï¸ åˆæ ¼" if ratio <= 20 else ("â–² æ³¨æ„" if ratio <= 30 else "âŒ ä¸åˆæ ¼")

        st.markdown(f"ğŸ“Š **ãƒ†ã‚­ã‚¹ãƒˆå æœ‰ç‡: {ratio}%**  {status}")
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
            reset_image()
            st.stop()


        overlay = draw_overlay(
            img_data,
            occupied_set,
            target_set,
            excluded_set,
            st.session_state["product_mask"]
        )
        st.image(overlay, caption="OCR + ã‚»ãƒ«ãƒãƒƒãƒ—", width=int(IMAGE_SIZE * 0.8))

    # ---------- å³ã‚«ãƒ©ãƒ  ----------
    with col2:
        # ---- é™¤å¤–ãƒã‚¹ãƒ•ã‚©ãƒ¼ãƒ  ----
        st.markdown("### ğŸ› ï¸ é™¤å¤–ãƒã‚¹ã‚’é¸æŠ")
        with st.form("form_exclusion"):
            if "temp_excluded" not in st.session_state:
                st.session_state["temp_excluded"] = list(excluded_set)

            for row_cells in group_cells_by_row(occupied_set):
                if not row_cells:
                    continue
                cols = st.columns([0.1] * len(row_cells), gap="small")
                for i, cid in enumerate(row_cells):
                    with cols[i]:
                        checked = cid in st.session_state["temp_excluded"]
                        val = st.checkbox(cid, value=checked, key=f"exclude_{cid}")
                        if val and cid not in st.session_state["temp_excluded"]:
                            st.session_state["temp_excluded"].append(cid)
                        if not val and cid in st.session_state["temp_excluded"]:
                            st.session_state["temp_excluded"].remove(cid)

            if st.form_submit_button("ğŸ”„ é™¤å¤–åæ˜ "):
                st.session_state["excluded_cells"] = list(st.session_state["temp_excluded"])

        st.markdown("---")
        # ---- å¯¾è±¡ãƒã‚¹ãƒ•ã‚©ãƒ¼ãƒ  ----
        st.markdown("### ğŸ› ï¸ å¯¾è±¡ãƒã‚¹ã‚’é¸æŠ")
        with st.form("form_target"):
            if "temp_target" not in st.session_state:
                st.session_state["temp_target"] = list(target_set)

            candidate_cells = sorted(get_all_cells() - occupied_set)
            for row_cells in group_cells_by_row(candidate_cells):
                if not row_cells:
                    continue
                cols = st.columns([0.1] * len(row_cells), gap="small")
                for i, cid in enumerate(row_cells):
                    with cols[i]:
                        checked = cid in st.session_state["temp_target"]
                        val = st.checkbox(cid, value=checked, key=f"target_{cid}")
                        if val and cid not in st.session_state["temp_target"]:
                            st.session_state["temp_target"].append(cid)
                        if not val and cid in st.session_state["temp_target"]:
                            st.session_state["temp_target"].remove(cid)

            if st.form_submit_button("ğŸ”„ å¯¾è±¡åæ˜ "):
                st.session_state["target_cells"] = list(st.session_state["temp_target"])

else:
    st.info("ç”»åƒãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
